# Подготовка датасета
На данном этапе просто скачал с github датасет и обработал по опубликованным в ToxiCR словарям с сокращениями и с регулярными выражениями токсичных слов

```python
python3 main.py --input code-review-dataset-full.xlsx -o preprocessed_dataset
```

# Использование моделей
## Классические методы
Выбрал Logistic Regression с TfidfVectorizer.
Проверял на 10-фолдовой кросс-валидации с построением матрицы несоответствия.
Изначальный запуск на $max\_features=5000$ дал результаты:

* Средняя точность: 0.88593501221936
* Стандартное отклонение: 0.0067367313008974715
* Матрица несоответсвия:

| 1025 | 14  |
|------|-----|
| 139  | 113 |

Для экспермиентирования начал с $max\_features$, с меньшим значением в 4000 результат улучшился:

* Средняя точность: 0.8864628645542486
* Стандартное отклонение: 0.006585574683682698
* Матрица несоответсвия:

| 1025 | 14  |
|------|-----|
| 137  | 115 |

Это может быть связано с тем, что на большем количестве фичей датасета не хватает и дополнительные фичи зашумляют  результат.

Дальше менял $ngram\_range, max\_df, min\_df, penalty$, прирост метрик оказался лучше всего на $C$ (параметре обратной регуляризации). Для $C=2$:

* Средняя точность: 0.897242027392983
* Стандартное отклонение: 0.007503768272972435
* Матрица несоответствия:

| 1023 | 16  |
|------|-----|
| 118  | 134 |


## Использование CodeBert

В качестве модели была выбрана *microsoft/codebert-base*.
В обработанном датасета колонка *is_toxic* была подменена на *label* и при помощи Trainer была проведена тренировка модели на 3 эпохах с *batch_size/eval_batch_size* 16.

Для запуска была добавлена опция *train-codebert*, команда запуска:

```python
python3 main.py train-codebert -d preprocessed_dataset/ -m microsoft/codebert-base
```

Оценка проводилась по `accuracy` и `precision_recall_fscore_support`, запуск производился на `NVIDIA GeForce RTX 4090`, результаты тренировки:

| Epoch | Eval Loss | Accuracy | Precision | Recall | F1 Score | Runtime (s) | Samples/sec | Steps/sec |
|-------|-----------|---------|-----------|--------|----------|-------------|------------|-----------|
| 1     | 0.2008    | 0.9241  | 0.7949    | 0.8141 | 0.8044   | 2.2492      | 1147.519   | 72.026    |
| 2     | 0.2036    | 0.9279  | 0.7866    | 0.8566 | 0.8201   | 2.2408      | 1151.801   | 72.294    |
| 3     | 0.2545    | 0.9283  | 0.7992    | 0.8364 | 0.8174   | 2.2397      | 1152.398   | 72.332    |

Видно, что модель хорошо показывает себя изначально, а на 3 эпохе слабый прирост *accuracy* при изменении *loss*, что может говорить о том, что модель близка к переобучению.

*F1* и *accuracy* хорошо растут. Рост *loss* вместе с ростом *accuracy* может указывать на то, что модель стала более уверенной в своих предсказаниях в условиях class imbalance. Что может быть правдой поскольку в датасете в большинстве своем нетоксичные комментарии (~4 раза больше).